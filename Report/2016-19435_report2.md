To implement the logging function for case 1, I created task_read_write_logger function in Logger.h and Logger.cpp
I gave 3 parameters, first the name of the task, then TaggedData pointer, and DelayedData pointer.
First the function checks if the given parameter matches with the task that we want to log.
The task that we want to log is given as input in settings.txt, and it is stored as utils::log_task.
The function checks if the parameter matches with utils::log_task. Then it opens the log file as ofstream.
If the TaggedData pointer is valid, we use the TaggedData member attributes and log the read data according to the format.
Similarly, if the DelayedData pointer is valid, we use the DelayedData member attributes to log the write data according to the format.
Then we close the ofstream and the function ends.

We implement the function in Job.cpp at the run_function() function. In the run_function(), it reads or writes data and creates TaggedData or DelayedData objects.
When the objects are created, we take the pointers of the object, and with the task name of the job returned by this->get_task_name(), we give the pointers as parameters of the above function.
If either of Tagged or Delayed data is not created, we give nullptr instead. So, at the moment when the data is read or written, data objects are created with their corresponding data, and we use those objects to implement our log.
While opening the ofstream, I used std::ios::app, so after 1 simulation, the log needs to be deleted. It can be implemented in main.cpp by checking if a log exists, and if so deleting it.

To implement the logging function for case 2, I created real_cyber_event_logger function in Logger.h and Logger.cpp
I used the same parameters as given in the lecture slides. After opening the ofstream of the log file, I simply wrote the information onto the ofstream.
In Executer.cpp, run_simulation() is the main function that simulates the given lists of jobs. At the 132nd line, the function checks whether a job in the vector of simulating jobs has no deterministic predecessor, hasn't been simulated, and hasn't been released. 
Then it releases the job, and at that moment we call the logging function, and using job->get_actual_release_time(), and job->get_job_ID(), we can get the release time and job id. We mark the event type as RELEASED.
Then the function goes through jobs in simulation_ready_queue. It selects a job and starts simulating. At that moment, using the member methods of run_job object, we obtain the start time and job id. We mark the event type as STARTED, and call the logging function.
After that, the function finishes the simulation. Then we check the occurence of deadline miss by comparing run_job->get_actual_finish_time() and run_job->get_actual_deadline. Like before, using member methods, we obtain the finish time and job id, and the event type is marked as FINISHED, or FINISHED (DEADLINE MISS) if deadline miss occurred. We call the logging function to record the information.
Similar to task_read_write_logger, I used std::ios::app, so the function keeps on appending information. So, after 1 simulation the log needs to be deleted. The implementation method is similar to task_read_write_logger.